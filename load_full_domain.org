#+title: Procedure for Creating Multi fidelity Domain using discrete tables
#+AUTHOR: Panayotis Manganaris
#+EMAIL: pmangana@purdue.edu
#+PROPERTY: header-args :session mrg :kernel mrg :async yes :pandoc org :results raw drawer
* Load Data
#+begin_src jupyter-python
  pbeq = "SELECT * FROM mannodi_pbe2"
  hseq = "SELECT * FROM mannodi_hse2"
  hscq = "SELECT * FROM mannodi_hsc2"
  phcq = "SELECT * FROM mannodi_phc"
  almora_q = "SELECT * FROM almora"
  ref_q = "SELECT * FROM mannodi_ref_elprop"
  with sqlite3.connect(os.path.expanduser("~/src/cmcl/cmcl/db/perovskites.db")) as conn:
      pbeold = pd.read_sql(pbeq, conn, index_col="index")
      hseold = pd.read_sql(hseq, conn, index_col="index")
      hscold = pd.read_sql(hscq, conn, index_col="index")
      phcold = pd.read_sql(phcq, conn, index_col="index")
      almoraold = pd.read_sql(almora_q, conn, index_col='index')
      lookup = pd.read_sql(ref_q, conn, index_col='index').set_index("Formula")
#+end_src

#+RESULTS:
:results:
:end:

#+begin_src jupyter-python
  pbe.read_csv("~/data/perovskites/current/pbe.csv", index_col=0, header=0)
  pbe = pd.read_csv('~/data/perovskites/pbe.')
  hse = pd.read_sql(hseq, conn, index_col="index")
  hsc = pd.read_sql(hscq, conn, index_col="index")
  phc = pd.read_sql(phcq, conn, index_col="index")
  almora = pd.read_sql(almora_q, conn, index_col='index')
#+end_src

#+RESULTS:
:results:
:end:

* clean data
** manipulations per column
#+begin_src jupyter-python
  almora_num = almora.columns[[1,2,3,4,5]].to_list()
  phc_num = phc.columns[[2,3,4,5]].to_list()
  hsc_num = hsc.columns[[2,3]].to_list()
  hse_num = hse.columns[[2,4,5,6,7]].to_list()
  pbe_num = pbe.columns[[2,4,5,6,7,8,9,10,11]].to_list()

  almora_obj = [col for col in almora.columns if col not in almora_num]
  phc_obj = [col for col in phc.columns if col not in phc_num]
  hsc_obj = [col for col in hsc.columns if col not in hsc_num]
  hse_obj = [col for col in hse.columns if col not in hse_num]
  pbe_obj = [col for col in pbe.columns if col not in pbe_num]
#+end_src

#+RESULTS:
:results:
:end:

** control dtypes
#+begin_src jupyter-python
  #used to drop nans in desired target
  pbe[pbe_num] = pbe[pbe_num].applymap(pd.to_numeric, errors='coerce')
  hse[hse_num] = hse[hse_num].applymap(pd.to_numeric, errors='coerce')
  almora[almora_num] = almora[almora_num].applymap(pd.to_numeric, errors='coerce')
  hsc[hsc_num] = hsc[hsc_num].applymap(pd.to_numeric, errors='coerce')
  phc[phc_num] = phc[phc_num].applymap(pd.to_numeric, errors='coerce')  
#+end_src

#+RESULTS:
:results:
:end:

* for fidelity comparisons
** define collection operation dictionaries
#+begin_src jupyter-python
  def make_ops(obj, num):
      ops = {**dict(zip(obj, ['first']*len(obj))), **dict(zip(num, ['median']*len(num)))}
      return ops

  almora_ops = make_ops(almora_obj, almora_num)
  phc_ops = make_ops(phc_obj, phc_num)
  hsc_ops = make_ops(hsc_obj, hsc_num)
  hse_ops = make_ops(hse_obj, hse_num)
  pbe_ops = make_ops(pbe_obj, pbe_num)
#+end_src

#+RESULTS:
:results:
:end:

** trim and aggregate possible targets
repeated record measures are aggregated
#+begin_src jupyter-python
  almora = almora.groupby('Formula').agg(almora_ops).reset_index(drop=True)
  pbe = pbe.groupby('Formula').agg(pbe_ops).reset_index(drop=True)
  hse = hse.groupby('Formula').agg(hse_ops).reset_index(drop=True)
  hsc = hsc.groupby('Formula').agg(hsc_ops).reset_index(drop=True)
  phc = phc.groupby('Formula').agg(phc_ops).reset_index(drop=True)
#+end_src

#+RESULTS:
:results:
:end:

#+begin_src jupyter-python
  almora.dropna(subset=almora_num, how='all', inplace=True)
  pbe.dropna(subset=pbe_num, how='all', inplace=True)
  hse.dropna(subset=hse_num, how='all', inplace=True)
  hsc.dropna(subset=hsc_num, how='all', inplace=True)
  phc.dropna(subset=phc_num, how='all', inplace=True)
#+end_src

#+RESULTS:
:results:
:end:

* Clean Data and label
going forward we just assume that almora consists primarily of cubic phase crystals
** subset based on deviation from cubicity
#+begin_src jupyter-python
  exclude = ["Rb0.375Cs0.625GeBr3", "RbGeBr1.125Cl1.875", "K0.75Cs0.25GeI3", "K8Sn8I9Cl15"]
  pbe = pbe[~pbe.Formula.isin(exclude)]
  hse = hse[~hse.Formula.isin(exclude)]
  hsc = hsc[~hsc.Formula.isin(exclude)]
  phc = phc[~phc.Formula.isin(exclude)]
  almora = almora[~almora.Formula.isin(exclude)]
#+end_src

#+RESULTS:
:results:
:end:

** create LoT axis
#+begin_src jupyter-python
  pbe = pbe.assign(LoT='PBErel')
  hse = hse.assign(LoT='HSErel')
  hsc = hsc.assign(LoT='HSErel(SOC)')
  phc = phc.assign(LoT='HSE-PBE(SOC)')
  almora = almora.assign(LoT='EXP')
#+end_src

#+RESULTS:
:results:
:end:

* Compute Base
** Compute Composition Vectors
#+begin_src jupyter-python
  pbec = pbe.ft.comp().iloc[:, :14:]
  hsec = hse.ft.comp().iloc[:, :14:]
  hscc = hsc.ft.comp().iloc[:, :14:]
  phcc = phc.ft.comp().iloc[:, :14:]
  ec = almora.ft.comp()
#+end_src

#+RESULTS:
:results:
:end:

** validate compositions
#+begin_src jupyter-python
  def validate_composition(df, cdf):
        if hasattr(df, 'sim_cell'):
              size = df.sim_cell.isin(["2x2x2"])
        else:
              size = [True]*df.shape[0]
        cdf = cdf.collect.abx()
        g = cdf.groupby(level=0, axis=1).sum()
        vB, vX, vA, = g.A.isin([1, 8]), g.B.isin([1, 8]), g.X.isin([3, 24])
        #subset indexes
        focus = size*vB*vA*vX
        return df[focus], cdf[focus]
#+end_src

#+RESULTS:
:results:
:end:

#+begin_src jupyter-python
  pbe, pbec = validate_composition(pbe, pbec)
  hse, hsec = validate_composition(hse, hsec)
  hsc, hscc = validate_composition(hsc, hscc)
  phc, phcc = validate_composition(phc, phcc)
  ec = ec.applymap(pd.to_numeric, errors='coerce') #drop symbolics
  almora, ec = validate_composition(almora, ec)
#+end_src

#+RESULTS:
:results:
:end:

** Compute Site Properties
#+begin_src jupyter-python
  pbep = join3(pbe.Formula.to_frame(), pbec, lookup, thru='element', right_on='Formula').reset_index(drop=True)
  hsep = join3(hse.Formula.to_frame(), hsec, lookup, thru='element', right_on='Formula').reset_index(drop=True)
  ep = join3(almora.Formula.to_frame(), ec, lookup, thru='element', right_on='Formula').reset_index(drop=True)
  hscp = join3(hsc.Formula.to_frame(), hscc, lookup, thru='element', right_on='Formula').reset_index(drop=True)
  phcp = join3(phc.Formula.to_frame(), phcc, lookup, thru='element', right_on='Formula').reset_index(drop=True)
#+end_src

#+RESULTS:
:results:
:end:

* Unify Domain
Base Domain may be mutated based on feature's Predictive Power by individual pipelines
** Basic Domains
#+begin_src jupyter-python
  my = pd.concat([pbe, hse, almora, hsc, phc], axis=0).reset_index(drop=True)

  mc = pd.concat([pbec, hsec, ec, hscc, phcc], axis=0).reset_index(drop=True)
  mp = pd.concat([pbep, hsep, ep, hscp, phcp], axis=0).reset_index(drop=True)
  mm = pd.concat([mc, mp, my.LoT], axis=1) #take phase and Lot information from ytables
  mc.columns = list(map(str, mc.columns))
  mp.columns = list(map(str, mp.columns))
  mm.columns = list(map(str, mm.columns))
#+end_src

#+RESULTS:
:results:
:end:

** unified categorical features
#+begin_src jupyter-python
  def make_category_labels(target):
      mixlog = target.ft.comp().collect.abx().groupby(level=0, axis=1).count()
      mix = mixlog.pipe(Categories.logif, condition=lambda x: x>1, default="pure", catstring="and")

      organics = target.ft.comp().collect.org()
      orglog = organics.groupby(level=0, axis=1).count()
      org = orglog.pipe(Categories.logif, condition=lambda x: x>=1, default="error", catstring="_&_")
      return mix, org

  mix, org = make_category_labels(my)
  my = my.assign(mix=mix).assign(org=org)
#+end_src

#+RESULTS:
:results:
:end:

** filter out BandX
#+begin_src jupyter-python
  mixfilter = my.mix.isin(['A', 'B', 'X', 'pure'])
  mm = mm[mixfilter]
  my = my[mixfilter]
#+end_src

#+RESULTS:
:results:
:end:

* Separate Domains
easy to do, but can be set up here if needed
** trim domains to apply multifi models to single-fi datasets
#+begin_src jupyter-python
  #py = my[my.LoT=='pbe']
  #pf = mm[my.LoT=='pbe']
#+end_src

#+RESULTS:
:results:
:end:
