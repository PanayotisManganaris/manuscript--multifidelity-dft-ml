% Created 2022-08-21 Sun 16:16
% Intended LaTeX compiler: pdflatex
\documentclass[aip, jmp, amsmath, amssymb]{revtex4-2}
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage{graphicx}
\usepackage{longtable}
\usepackage{wrapfig}
\usepackage{rotating}
\usepackage[normalem]{ulem}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{capt-of}
\usepackage{hyperref}

\usepackage{abstract} %% easy abstract environment (from frontmatter pkg "ltxfront")
\usepackage[export]{adjustbox} %% expanded control over image, minipages, etc
\usepackage{amsthm} %% formal mathematics environments
\usepackage{amsfonts} %% formal math fonts
\usepackage{mathptmx} %% ghostscript/postscript fonts and font loading options
\usepackage{bm} %% bold math
\usepackage{caption} %% full (expands on capt-of) control over appearance of float captions
%\captionsetup{margin=10pt, font=small, labelfont=bf} %% (global preamble, local env)
\usepackage{sidecap} %% control of figure and caption positioning and margin spill
\usepackage{mathtools} %% bugfixing and additional tools for amsmath
\usepackage{upgreek} %% easy lower and uppercase nonitalicized greek letters
\usepackage{soul} %% spaceout and underline macros
\usepackage{xcolor} %% text color macros
%\usepackage{natbib} %% required citation engine

%% control margin configurations and visualize framing
%\usepackage[showframe, %%Uncomment any one of the following lines to test
%%scale=0.7, marginratio={1:1, 2:3}, ignoreall, %% default settings
%%text={7in,10in},centering,
%%margin=1.5in,
%%total={6.5in,8.75in}, top=1.2in, left=0.9in, includefoot,
%%height=10in,a5paper,hmargin={3cm,0.8in},
%]{geometry}

%\usepackage[mathlines]{lineno}% Enable numbering of text and display math
%\linenumbers\relax % Commence numbering lines
\author{Panayotis Manganaris}
\date{\today}
\title{}
\hypersetup{
 pdfauthor={Panayotis Manganaris},
 pdftitle={},
 pdfkeywords={},
 pdfsubject={},
 pdfcreator={Emacs 29.0.50 (Org mode 9.5.2)}, 
 pdflang={English}}
\begin{document}

%revtex frontmatter conventions for quick recall via INCLUDE keyword
\title{%
Combining High-Throughput Computations, Surrogate Models, and\\
Genetic Algorithms for Discovering Novel Halide Perovskites
}
%\thanks{A footnote to the article title}

\author{Panayotis Manganaris}
\author{Jiaqi Yang}
\author{Arun \surname{Mannodi Kanakkithodi}}
\email{amannodi@purdue.edu}
\affiliation{%
School of Materials Engineering,\\
Purdue University, West Lafayette, Indiana 47907, USA
}
\collaboration{Mannodi Research Group}

\date{\today}
\maketitle
%INCLUDE before abstract environment
\begin{abstract}
We report on the details of creating a materials design pipeline for
halide perovskites. The primary objective of this pipeline is to
recommend perovskite alloy compositions corresponding to targeted
properties. Here targets are chosen to yield stable compounds with
high photovoltaic (PV) performance. Thus, we focus on models of the
electronic band gap, decomposition energy (and, therefore, perovskite
stability), and PV efficiency. We use the Spectroscopic Limited
Maximum Efficiency (SLME) for synthetic data and Power Conversion
Efficiency (PCE) for physical data. We leverage nanoHUB, an
NSF-funded, Purdue-hosted computational repository, to host literate
and reproducible notebooks documenting our model development workflow
\cite{manganaris-2022-mrs-comput}. We also host an interoperable
database and continuously improving inverse design pipeline for public
access. We thus enable the scientific community to search for
compounds satisfying performance targets for a wide range of
optoelectronic applications, including quantum computing and
metrology. The design pipeline makes recommendations based on
continuous surrogate models trained to connect a discretely sampled
composition space to the targeted properties. Optimal compositions are
selected using a Genetic Algorithm (GA) where fitness is judged by
minimizing the euclidean distance between the predicted and targeted
properties and by ensuring chemical feasibility of the composition.

The use of GA allows the optimizer to prioritize exploration. So,
locally optimal candidate compositions can be discovered without
excessive fixation on a small subset of fit regions. Critically, GA is
also efficient in high dimensional space. In our past published work
\cite{mannodi-kanakkithodi-2021-data-driven-new}, the mixed composition
space of all possible perovskite alloys experiences combinatorial
scaling. As we transition from discrete sampling based on a finite
supercell space to continuous surrogate models, this scaling continues
to infinite resolution. We provide a variety of surrogate machine
learning (ML) models for the optimizer to work on, namely a rigorously
optimized Random Forest Regressor (RFR), a Gaussian Process (GP)
Regressor, and a Sure Independence Screening and Sparsifying Operator
(SISSO) regressor. Naturally, the GA's solutions will only be as good
as the accuracy of the surrogates.

The data base consists of approximately 1000 records subdivided into
tables according to the record sources. The largest table of \textasciitilde{}500
compounds contains optoelectronic properties computed using density
functional theory (DFT) simulations (including geometry optimization
of pseudo-cubic supercells of ABX3 compounds with arbitrary mixing at
each site, followed by static band structure and optical absorption
calculations) performed at the GGA-PBE level of theory. Following
this, \textasciitilde{}300 compounds were subjected to more expensive hybrid HSE06
computations, both with and without spin-orbit coupling (SOC), for
better electronic properties. Finally, \textasciitilde{}100 of the same compositions
also record experimental measurements for band gap and efficiency.

So, we explore combining these sources according to various
multi-fidelity modeling techniques with the aim of improving the
accuracy of each of our surrogate architectures. Currently we ignore
descriptors based on crystal structure and use only composition
information. This simplifies featurization because a composition
vector can be procedurally obtained for experimental and synthetic
data alike simply by parsing a string encoding the ABX\textsubscript{3} perovskite
formula corresponding to each record with relative ease.

This 14-dimensional vector is a sufficient predictor variable, Nothing
more is needed for a new data point to be evaluated. However, we also
examine 36 additional predictor variables computed as linear
combinations of these compositions and certain elemental properties
obtained from the trusted Mendeleev databases
\cite{mentel-2014}. Previous reports on the union of all 50 of these
predictor variables
\cite{yang-2022-high-throug,mannodi-kanakkithodi-2021-data-driven-new}.
show that our perovskites database is a good systematic sampling of
the solutions space and contains a variety of strong correlations
between the predictor and regressor variables.

In summary, this framework provides on-demand predictions for the
stability and optoelectronic properties of any perovskite alloy based
on rigorously optimized ML models. It also recommends novel
compositions with multiple desired properties using these models.  By
testing these recommendations with DFT we form a loop that leverages
ML's ability to improve incrementally with exposure to new data that
efficiently discovers the best possible materials.

Finally, we discuss the advantages and disadvantages of state of the
art graph-descriptor driven surrogate models for this application.
Our database is constructed to leverage these graph tools as well, so
we expect future versions of this system to benefit from their
implementation. Ultimately, our framework is openly available and
constantly being updated with fresh DFT data, ML models, and tools for
prediction and design.
\end{abstract}
\section*{Introduction}
\label{sec:org5c779e9}
\subsection*{Materials Design Pipeline}
\label{sec:orged9b7f0}
\begin{figure}[htbp]
\centering
\includegraphics[width=.9\linewidth]{Figure1.pdf}
\caption{\label{fig:outline} \textbf{Basic outline, structure and properties.} (a) General outline of materials design process leading to ML-driven prediction of properties based on DFT data and intermediate step of converting materials to numerical descriptors. (b) The Zinc Blende structure adopted by CdTe, CdSe, and CdS. Cd atoms are shown in blue and Te/Se/S atoms in red. The unit cell has been indicated with dashed lines. (c) Comparison of band gaps computed at the PBE and HSE06 levels of theory with reported experimental values \cite{kim-2014-cdses-nanow,swanson-2017-co-sublim}, for CdTe, CdSe, CdS, CdTe\textsubscript{0.5}Se\textsubscript{0.5} and CdSe\textsubscript{0.5}S\textsubscript{0.5}. (d) Outline of the DFT and ML driven prediction of properties of impurities in Cd-based chalcogenides.}
\end{figure}
\subsection*{Dataset Overview}
\label{sec:org11fefaa}
\subsubsection*{Quick visualization of PBE data + correlations with descriptors}
\label{sec:org002f6ff}
(reproduced from other paper?).\\
\subsubsection*{Distribution Analysis}
\label{sec:orgf398b24}
The design of this dataset provides an opportunity to assess the
generalizability of Perovskite property models with respect to alloy
group. It also provides an opportunity to investigate the statistical
impact of constituent compounds on Perovskite property performance.

This will be done by performing model optimization on random
cross-validation folds as well as on 

\begin{itemize}
\item PBE Data
\label{sec:org1ccfd76}
\href{Constituent\_Representations.png}{\begin{figure}[htbp]

\includegraphics[width=.9\linewidth]{./Dataset_Overview/PBE_Constituent_Representations.png}
\caption{\label{fig:comp} Proportion of constituents present in dataset}
\end{figure}}

\href{Alloy\_Representations.png}{\begin{figure}[htbp]

\includegraphics[width=.9\linewidth]{./Dataset_Overview/PBE_Alloy_Representations.png}
\caption{\label{fig:group} Share of total data apportioned to each alloy group}
\end{figure}}

\begin{figure}[htbp]
\centering
\includegraphics[width=.9\linewidth]{./Dataset_Overview/PBE_Constituent_Representations_per_Scheme.png}
\caption{\label{fig:groupcomp} Proportion of constituents present in each alloy group}
\end{figure}

\item HSE Data
\label{sec:org31edb6e}
\href{Constituent\_Representations.png}{\begin{figure}[htbp]

\includegraphics[width=.9\linewidth]{./Dataset_Overview/HSE_Constituent_Representations.png}
\caption{\label{fig:comp} Proportion of constituents present in dataset}
\end{figure}}

\href{Alloy\_Representations.png}{\begin{figure}[htbp]

\includegraphics[width=.9\linewidth]{./Dataset_Overview/HSE_Alloy_Representations.png}
\caption{\label{fig:group} Share of total data apportioned to each alloy group}
\end{figure}}

\begin{figure}[htbp]
\centering
\includegraphics[width=.9\linewidth]{./Dataset_Overview/HSE_Constituent_Representations_per_Scheme.png}
\caption{\label{fig:groupcomp} Proportion of constituents present in each alloy group}
\end{figure}
\end{itemize}

\subsubsection*{Univariate Analysis}
\label{sec:orgc983119}
The computational properties of interest are Perovskite Bandgap,
Decomposition Energy (stability), and SpeSLME. appear to follow an
approximately normal distribution Bandgap and

\subsection*{Software Tools}
\label{sec:org4cb238c}
A couple of libraries are in development for easing the aggregation,
accessing, sharing, and analysis of this data.  The database itself is
packaged with "cmcl" at \url{http://github.com/PanayotisManganaris/cmcl}.
In this early stage of development, cmcl strives to provide an
"inquisitive" interface to comprehensive chemical data feature
computers in the style of the pandas API. At its current stage, it has
been useful for extracting composition vectors from the formula
strings identifying each compound we explored.

Model development is performed using the intel distribution of python
and SciKit Learn v0.24 and a standard distribution of Tensorflow both
obtained from the anaconda repositories. A library of supplementary
model evaluation tools (designed with particular attention to
smoothing the use of Pandas in ML workflows) is being maintained in
the "yogi" repository at \url{http://github.com/PanayotisManganaris/yogi}

\section*{RESULTS AND DISCUSSION}
\label{sec:orgd6c0d83}
Future work will focus on applying and extending the high throughput
screening criteria developed in \cite{mannodi-kanakkithodi-2021-data-driven-new}


\subsection*{Outline of Work}
\label{sec:org49f050d}
Computational Details
\begin{itemize}
\item HT-DFT Data Generation
The current work is focused on cubic phase compounds only.
\item Experimental Data Collection
\item Data Validation
some records were excluded from the present analysis based on an
excessive deviation-from-cubicity as measured by:

DFC Equations
\end{itemize}

Descriptors and correlations
\begin{itemize}
\item physical aspect of numerical descriptors
\end{itemize}

Several machine learning architectures are rigorously optimized with
regard to both generality over the domains of Perovskite compositions
and site-averaged atomic properties and generality over the domain of
alloy classifications.

In order to control for the classification biases potentially acting
on the parameter space of regression models, nine metrics are used to
evaluate the performance of each model over all alloy types at every
stage of the hyper-parameter optimization simultaneously. Only models
that perform uniformly well on all alloy classes are selected.

Validation curves are computed for hyper-parameters to which a given
model is particularly sensitive.



RFR, GPR, GBR
 Inverse design using Genetic Algorithm \(\rightarrow\)
Validation of promising compounds.\\


\subsection*{All surrogate ML model results}
\label{sec:org8534dc0}

\begin{itemize}
\item RMSE vs training set size for NN, RFR and GPR, using composition only,
elemental only, and both together, for 3 properties: \textbf{decomposition
energy, band gap, SLME}.

\item Best RMSE values for each property for different ML techniques and
different descriptors

\item Parity plots for best ML models for each property
\end{itemize}

\subsection*{Genetic algorithm results}
\label{sec:orgaa3f4d7}

\begin{itemize}
\item Fitness score vs generation, stability only.

\item Fitness score vs generation, stability + band gap.

\item Fitness score vs generation, stability + band gap + SLME.

\item Performance of GA with NN/GPR/RFR and with comp/elem/comp+elem.\\
\end{itemize}

\textbf{Figure5:}\\
Validation using new DFT calculations on 10 compositions in 4x4x4
supercell. DFT vs ML properties + band structure + absorption spectra.\\

\subsection*{\ldots{}}
\label{sec:orgc05ecba}
\begin{center}
\begin{tabular}{llrrr}
\textbf{Dataset} & \textbf{Regression} & \textbf{Site Properties} & \textbf{Defect Properties} & \textbf{Site+Defect}\\
\hline
 &  &  &  & \\
 & RFR & 0.40 & 0.20 & 0.17\\
Training & KRR & 0.40 & 0.30 & 0.20\\
 & LASSO & 0.62 & 0.50 & 0.44\\
 &  &  &  & \\
 &  &  &  & \\
 & RFR & 0.65 & 0.45 & 0.38\\
Test & KRR & 0.68 & 0.40 & 0.32\\
 & LASSO & 0.75 & 0.52 & 0.47\\
 &  &  &  & \\
 &  &  &  & \\
 & RFR & 0.84 & 0.57 & 0.52\\
CdTe\(_{0.5}\)Se\(_{0.5}\) & KRR & 0.80 & 0.65 & 0.57\\
 & LASSO & 0.95 & 0.73 & 0.65\\
 &  &  &  & \\
 &  &  &  & \\
 & RFR & 0.86 & 0.63 & 0.57\\
CdSe\(_{0.5}\)S\(_{0.5}\) & KRR & 0.75 & 0.68 & 0.70\\
 & LASSO & 0.92 & 0.70 & 0.72\\
 &  &  &  & \\
\end{tabular}
\end{center}

\subsection*{Summary}
\label{sec:org6b55a79}
\ldots{}\\

\section*{METHODS}
\label{sec:org8b88a7b}
\subsection*{DFT Details}
\label{sec:orgfa9b9d0}
\ldots{}\\

\subsubsection*{{\bfseries\sffamily TODO} Chemical Featurization}
\label{sec:orgccd0710}

\subsection*{Surrogate Modeling Perovskite Properties}
\label{sec:org03d60c9}
\subsubsection*{Objectives}
\label{sec:org6df1a3c}
Our objectives are two fold:

First, we aim to accurately predict performance-relevant Perovskite
band gaps, decomposition energies, and Spectroscopically Limited Maximum
Efficiency (SLME).

We will follow a multi-fidelity approach, where the bulk of affordable
low level-of-theory data will inform and improve the extrapolative
ability of models trained on higher fidelity measurements.

Our fidelity hierarchy climbs from results obtained using a PBE
functional, to results obtained using an HSE functional, to
experimental results aggregated in literature \cite{almora-2020-devic-perfor}.

We aim to express these variables as functions of the Perovskite
composition. Schemes for incorporating structural information will be
developed in future work. Nevertheless, a strong understanding of the
influence of chemical composition on performance will continue to be a
priority as it is expected to aid in screening the combinatorial
chemical space for viable compounds based on both available precursors
and performance criteria.

Furthermore, chemical data can already be mined for a rich feature set
as previously discussed.

Second, we hope to better understand the average physical impacts
of 1) site-specific alloying and 2) using organic molecules in the
Perovskite superstructure.

These goals are not entirely separate from the first goal of
expressing various properties as functions of composition, but they
can be more simply approached as problems of addressing dependencies
in the data statistics. Our model development will test the hypothesis
that formula that fall within one of these classifications will share
some distributed qualities with others that fit their classification.

These are certainly not the only groups of dependent samples
potentially generated by these experiments, but they are the most
noticeable in the structure of the multi-fidelity sample set as we
have constructed it.
\subsubsection*{Considerations}
\label{sec:org4a01818}
We expect that perovskites of a given alloy class and of a given
hybrid-organic/inorganic status will perform significantly
differently, in all respects, to Perovskites of a another class or
status. By leveraging the even distribution of constituent compounds
in this sample set of Halide Perovskites, we can cast this problem as
a series of cross-validations for independently trained models.

A minimum of 3-fold cross-validation is performed for every set of
model parameters that is considered. 

Two separate cross validation schemes are employed at each stage of
the design process.

First, the sample set is shuffled once and split to mitigate the
models tendency to fit on sample order, then, stratified K-folds are
generated in manner consistent with the classification of each
sample. However, this fold is not used in a classification problem,
the regressor is trained on the subsets of each class, and it's
ability to extrapolate is independently metered on each validation
fold consisting of members of the other classes.

Second, the ability for a model trained on samples belonging to one
class/status to extrapolate to samples of another class/status is
tested as well. The samples again are shuffled and split. then the
training set is separated using a grouping K-fold split strategy (stratified? shuffled?)

Per architecture, a model is instantiated using the, in aggregate,
best performing parameters. These models are finally validated against
the test sets originally split off from the sample in \textbf{both their
extrapolative ability and consistency across groups.}

\subsubsection*{Model Optimization Details}
\label{sec:org217195c}
The rigorous hyper-Parameter Optimization (HPO) of any feature
engineering and modeling pipeline is a problem discussed extensively
in the literature. HPO approaches can be broadly separated into
exhaustive and efficient optimization strategies
\cite{yang-2020-hyper-optim}. We use a two-stage procedure for
selecting the best model parameters.

The first stage is an exhaustive grid-search over diversely sampled
parameter space. Each combination of parameters instantiates a model
which is then fit to each of a set of stratified training subsets
generated by a 3-fold cross-validation strategy. Every fitted model is
subsequently tested against the cross-validation test sets and a suite
of regression scoring metrics are applied simultaneously.

The scoring metrics we choose vary by model architecture. See summary tables.

The grid search is then narrowed to a high performance quadrant of the
search space by the model evaluator based on recommendations made by a
simple entropy minimization algorithm implemented in the "yogi"
supplementary package under the yogi.model\textsubscript{selection.butler} module --
see documentation for the various grid-narrowing strategies available.

In general, the recommended grid quickly eliminates under-performing
settings based on the sample probability of a setting appearing in a
set of finalists according to the scoring rankings. The selection
score is additionally influenced by a weighted sum of the scoring
ranks allowing for considerably tuning of the selection criterion.
For best results, a few different grid spaces should be explored to
corroborate eliminations.

After the recommendation is made, the granularity of the grid is
increased in the remaining ambiguous parameters and the process is
repeated.

Additionally/Alternatively,

\subsection*{Genetic Algorithm}
\label{sec:org9543749}
\ldots{}\\

\section*{FUTURE WORK}
\label{sec:org5098265}
\begin{itemize}
\item must have identified novel compounds
\begin{itemize}
\item generalize the active learning strategy to include arbitrary structures
\end{itemize}
\item improve accuracy of surrogate model -- RFR/GPR/NN?
\begin{itemize}
\item incorporate experimental data \cite{jacobsson-2021-open-acces,briones-2021-accel-lattic}
\item improve delta learning strategy to utilize more indicators besides SLME/PCE
\end{itemize}
\item utilize the active learning approach developed here to extensively
grow the cubic perovskites dataset
\begin{itemize}
\item we will investigate using MEGnet or similar structure-based
predictors to also begin optimizing other phases in the same
fashion
\end{itemize}
\end{itemize}

Our first objective is to utilize much more experimental data in the
construction of regressions.
\section*{ACKNOWLEDGMENTS}
\label{sec:org79ed0a1}
We acknowledge funding from the US Department of Energy SunShot program
under contract \#DOE DEEE005956. Use of the Center for Nanoscale
Materials, an Office of Science user facility, was supported by the U.S.
Department of Energy, Office of Science, Office of Basic Energy
Sciences, under Contract No. DE-AC02-06CH11357. We gratefully
acknowledge the computing resources provided on Bebop, a
high-performance computing cluster operated by the Laboratory Computing
Resource Center at Argonne National Laboratory. This research used
resources of the National Energy Research Scientific Computing Center, a
DOE Office of Science User Facility supported by the Office of Science
of the U.S. Department of Energy under Contract No. DE-AC02-05CH11231.
MYT would like to acknowledge support from the U.S. Department of
Energy, Office of Science, Office of Workforce Development for Teachers
and Scientists (WDTS) under the Science Undergraduate Laboratory
Internship (SULI) program. MJD was was supported by the U. S. Department
of Energy , Office of Basic Energy Sciences, Division of Chemical
Sciences, Geosciences, and Biosciences, under Contract No.
DE-AC02-06CH11357.

\subsection*{Author Contributions}
\label{sec:orgb0acb02}
M.K.Y.C., R.F.K. and A.M.K. conceived the idea. A.M.K., M.Y.T. and
F.G.S. performed the DFT computations. A.M.K. and M.J.D. trained ML
models. All authors contributed to the discussion and writing of the
manuscript.

\subsection*{Data Availability}
\label{sec:org039858c}
DFT data and ML models are available from the corresponding author upon
reasonable request.

\subsection*{Additional Information}
\label{sec:org049acd3}
The authors declare no competing financial or non-financial interests.

Correspondence and requests for materials should be addressed to A.M.K.
(email:amannodi@purdue.edu).

\section*{REFERENCES}
\label{sec:orgebb792c}
\bibliographystyle{aipnum4-2}
\bibliography{../../../org/bibliotex/bibliotex}
\end{document}