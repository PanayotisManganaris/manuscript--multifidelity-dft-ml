% Created 2022-04-08 Fri 14:39
% Intended LaTeX compiler: pdflatex
\documentclass[11pt]{article}
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage{graphicx}
\usepackage{longtable}
\usepackage{wrapfig}
\usepackage{rotating}
\usepackage[normalem]{ulem}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{capt-of}
\usepackage{hyperref} %% need to eliminate this section from the automated export
%% Template for a preprint Letter or Article for submission
%% to the journal Nature.
%% Written by Peter Czoschke, 26 February 2004
%%

%\documentclass[aip]{nature}

%\documentclass[]{article}

\documentclass[]{revtex4-2}

% aip, onecolumn, amsmath, amssymb, reprint]{revtex4-1}

%{revtex4-1}

\usepackage{graphicx}% Include figure files
\usepackage{dcolumn}% Align table columns on decimal point
\usepackage{bm}% bold math
%\usepackage[mathlines]{lineno}% Enable numbering of text and display math
%\linenumbers\relax % Commence numbering lines
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage{mathptmx}
%\usepackage{multicol}
\usepackage[export]{adjustbox}
\usepackage{abstract}
\usepackage{graphicx}
\usepackage{caption}
\usepackage{amsmath}
\usepackage{amsthm}
\usepackage{amsfonts}
%\usepackage{float}
\usepackage{sidecap}
\usepackage{mathtools}
\usepackage{adjustbox}
\usepackage{ upgreek }
\usepackage{longtable}
\usepackage{wrapfig}
\usepackage{rotating}
\usepackage[normalem]{ulem}
\usepackage{fullpage}
\newcommand{\ssection}[1]{%
\section[#1]{\centering\normalfont\scshape #1}}
\newcommand{\ssubsection}[1]{%
\subsection[#1]{\bfseries\normalfont\scshape #1}}
\newcommand{\ssubsubsection}[1]{%
\ssubsubsection[#1]{\bfseries\normalfont\scshape #1}}
\renewcommand{\theequation}{\arabic{equation}}
\usepackage{soul,xcolor}
\usepackage{amssymb}
\usepackage{capt-of}
\usepackage{hyperref}
\hypersetup{
pdfauthor={},
pdftitle={},
pdfkeywords={},
pdfsubject={},
pdfcreator={Emacs 29.0.50 (Org mode 9.5.2)},
\date{\today}
\title{Combining High-Throughput Computations, Surrogate Models, and Genetic Algorithms for Discovering Novel Halide Perovskites}
\hypersetup{
 pdfauthor={},
 pdftitle={Combining High-Throughput Computations, Surrogate Models, and Genetic Algorithms for Discovering Novel Halide Perovskites},
 pdfkeywords={},
 pdfsubject={},
 pdfcreator={Emacs 29.0.50 (Org mode 9.5.2)}, 
 pdflang={English}}
\begin{document}

\maketitle
\tableofcontents

\author{Panayotis Manganaris, Jiaqi, Yang, Arun Mannodi-Kanakkithodi}
 \email{amannodi@purdue.edu}
\affiliation{School of Materials Engineering, Purdue University, West Lafayette, Indiana 47907, USA}%
\date{\today}

\maketitle

\begin{abstract}
\textbf{
The ability to predict the likelihood of impurity incorporation and
their electronic energy levels in semiconductors is crucial for
controlling its conductivity, and thus the semiconductor's performance
in solar cells, photodiodes, and optoelectronics. The difficulty and
expense of experimental and computational determination of impurity
levels makes a data-driven machine learning approach appropriate. In
this work, we show that a density functional theory-generated dataset
of impurities in Cd-based chalcogenides CdTe, CdSe, and CdS can lead
to accurate and generalizable predictive models of defect
properties. By converting any \textit{semiconductor + impurity} system
into a set of numerical descriptors, regression models are developed
for the impurity formation enthalpy and charge transition
levels. These regression models can subsequently predict impurity
properties in mixed anion CdX compounds (where X is a combination of
Te, Se and S) fairly accurately, proving that although trained only on
the end points, they are applicable to intermediate compositions. We
make machine-learned predictions of the Fermi-level-dependent
formation energies of hundreds of possible impurities in 5
chalcogenide compounds, and we suggest a list of impurities which can
shift the equilibrium Fermi level in the semiconductor as determined
by the dominant intrinsic defects. These `dominating' impurities as
predicted by machine learning compare well with DFT predictions,
revealing the power of machine-learned models in the quick screening
of impurities likely to affect the optoelectronic behavior of
semiconductors.
}
\end{abstract}
\section{Introduction}
\label{sec:orgee9d0b6}
\ldots{}\\

\begin{figure}[htbp]
\centering
\includegraphics[width=.9\linewidth]{Figure1.pdf}
\caption{\label{fig:outline} \textbf{Basic outline, structure and properties.} (a) General outline of materials design process leading to ML-driven prediction of properties based on DFT data and intermediate step of converting materials to numerical descriptors. (b) The Zinc Blende structure adopted by CdTe, CdSe, and CdS. Cd atoms are shown in blue and Te/Se/S atoms in red. The unit cell has been indicated with dashed lines. (c) Comparison of band gaps computed at the PBE and HSE06 levels of theory with reported experimental values \cite{Expt_gap1,Expt_gap2}, for CdTe, CdSe, CdS, CdTe\$\textsubscript{0.5}\$Se\(_{0.5}\) and CdSe\$\textsubscript{0.5}\$S\(_{0.5}\). (d) Outline of the DFT and ML driven prediction of properties of impurities in Cd-based chalcogenides.\}}
\end{figure}

\section{RESULTS AND DISCUSSION}
\label{sec:orge645445}
\textbf{Figure1:}\\
Outline of work: HT-DFT Data Generation \(\rightarrow\) Descriptors and
correlations \(\rightarrow\) Surrogate ML Models (NN, RFR, GPR)
\(\rightarrow\) Inverse design using Genetic Algorithm \(\rightarrow\)
Validation of promising compounds.\\
\textbf{Figure2:}\\
Quick visualization of PBE data + correlations with descriptors
(reproduced from other paper?).\\
\textbf{Figure3:}\\
All surrogate ML model results:

\begin{itemize}
\item RMSE vs training set size for NN, RFR and GPR, using composition only,
elemental only, and both together, for 3 properties: \textbf{decomposition
energy, band gap, SLME}.

\item Best RMSE values for each property for different ML techniques and
different descriptors

\item Parity plots for best ML models for each property
\end{itemize}


\textbf{Figure4:}\\
Genetic algorithm results:

\begin{itemize}
\item Fitness score vs generation, stability only.

\item Fitness score vs generation, stability + band gap.

\item Fitness score vs generation, stability + band gap + SLME.

\item Performance of GA with NN/GPR/RFR and with comp/elem/comp+elem.\\
\end{itemize}

\textbf{Figure5:}\\
Validation using new DFT calculations on 10 compositions in 4x4x4
supercell. DFT vs ML properties + band structure + absorption spectra.\\

\subsection{\ldots{}}
\label{sec:org3258682}
\subsection{\ldots{}}
\label{sec:org46a4e72}
\begin{center}
\begin{tabular}{llrrr}
\textbf{Dataset} & \textbf{Regression Method} & \textbf{Elemental properties} & \textbf{Unit cell defect properties} & \textbf{Elemental + Unit cell defect properties}\\
\hline
 &  &  &  & \\
 & RFR & 0.40 & 0.20 & 0.17\\
Training & KRR & 0.40 & 0.30 & 0.20\\
 & LASSO & 0.62 & 0.50 & 0.44\\
 &  &  &  & \\
 &  &  &  & \\
 & RFR & 0.65 & 0.45 & 0.38\\
Test & KRR & 0.68 & 0.40 & 0.32\\
 & LASSO & 0.75 & 0.52 & 0.47\\
 &  &  &  & \\
 &  &  &  & \\
 & RFR & 0.84 & 0.57 & 0.52\\
CdTe\(_{0.5}\)Se\(_{0.5}\) & KRR & 0.80 & 0.65 & 0.57\\
 & LASSO & 0.95 & 0.73 & 0.65\\
 &  &  &  & \\
 &  &  &  & \\
 & RFR & 0.86 & 0.63 & 0.57\\
CdSe\(_{0.5}\)S\(_{0.5}\) & KRR & 0.75 & 0.68 & 0.70\\
 & LASSO & 0.92 & 0.70 & 0.72\\
 &  &  &  & \\
\end{tabular}
\end{center}

\subsection{Summary}
\label{sec:org162439a}
\ldots{}\\

\section{METHODS}
\label{sec:org4bb5fe8}
\subsection{DFT Details}
\label{sec:orgd03eae7}
\ldots{}\\
\[\label{eqn-1}
\begin{multlined}
E^f(q,E$_{F}$) = E(D$^{q}$) - E(CdX) + \mu + q(E$_{F}$ + E$_{vbm}$) + E_{corr}
\end{multlined}\]

\[\label{eqn-2}
\begin{multlined}
{\epsilon}(q_1/q_2) = \frac{E^{f}(q_{1},E_F=0) - E^{f}(q_{2},E_F=0)}{q_{2}-q_{1}}
\end{multlined}\]

\subsubsection{{\bfseries\sffamily TODO} Chemical Featurization}
\label{sec:org783ad83}

\subsection{Surrogate Modeling Perovskite Properties}
\label{sec:org8638558}
\subsubsection{Objectives}
\label{sec:orge573b93}
Our objectives are two fold:

First, we aim to accurately predict performance-relevant Perovskite
band gaps, decomposition energies, and Spectroscopically Limited Maximum
Efficiency (SLME).

We will follow a multi-fidelity approach, where the bulk of affordable
low level-of-theory data will inform and improve the extrapolative
ability of models trained on higher fidelity measurements.

Our fidelity hierarchy climbs from results obtained using a PBE
functional, to results obtained using an HSE functional, to
experimental results aggregated in literature \cite{almora-2020-devic-perfor}.

We aim to express these variables as functions of the Perovskite
composition. Schemes for incorporating structural information will be
developed in future work. Nevertheless, a strong understanding of the
influence of chemical composition on performance will continue to be a
priority as it is expected to aid in screening the combinatorial
chemical space for viable compounds based on both available precursors
and performance criteria.

Furthermore, chemical data can already be mined for a rich feature set
as previously discussed.

Second, we hope to better understand the average physical impacts
of 1) site-specific alloying and 2) using organic molecules in the
Perovskite superstructure.

These goals are not entirely separate from the first goal of
expressing various properties as functions of composition, but they
can be more simply approached as problems of addressing dependencies
in the data statistics. Our model development will test the hypothesis
that formula that fall within one of these classifications will share
some distributed qualities with others that fit their classification.

These are certainly not the only groups of dependent samples
potentially generated by these experiments, but they are the most
noticeable in the structure of the multi-fidelity sample set as we
have constructed it.
\subsubsection{Considerations}
\label{sec:org8d694c8}
We expect that perovskites of a given alloy class and of a given
hybrid-organic/inorganic status will perform significantly
differently, in all respects, to Perovskites of a another class or
status. By leveraging the even distribution of constituent compounds
in this sample set of Halide Perovskites, we can cast this problem as
a series of cross-validations for independently trained models.

A minimum of 3-fold cross-validation is performed for every set of
model parameters that is considered. 

Two separate cross validation schemes are employed at each stage of
the design process.

First, the sample set is shuffled once and split to mitigate the
models tendency to fit on sample order, then, stratified K-folds are
generated in manner consistent with the classification of each
sample. However, this fold is not used in a classification problem,
the regressor is trained on the subsets of each class, and it's
ability to extrapolate is independently metered on each validation
fold consisting of members of the other classes.

Second, the ability for a model trained on samples belonging to one
class/status to extrapolate to samples of another class/status is
tested as well. The samples again are shuffled and split. then the
training set is separated using a grouping K-fold split strategy (stratified? shuffled?)

Per architecture, a model is instantiated using the, in aggregate,
best performing parameters. These models are finally validated against
the test sets originally split off from the sample in \textbf{both their
extrapolative ability and consistency across groups.}

\subsubsection{Model Optimization Details}
\label{sec:orgb365103}
The rigorous hyper-Parameter Optimization (HPO) of any feature
engineering and modeling pipeline is a problem discussed extensively
in the literature. HPO approaches can be broadly separated into
exhaustive and efficient optimization strategies
\cite{yang-2020-hyper-optim}. We use a two-stage procedure for
selecting the best model parameters.

The first stage is an exhaustive grid-search over diversely sampled
parameter space. Each combination of parameters instantiates a model
which is then fit to each of a set of stratified training subsets
generated by a 3-fold cross-validation strategy. Every fitted model is
subsequently tested against the cross-validation test sets and a suite
of regression scoring metrics are applied simultaneously.

The scoring metrics we choose vary by model architecture. See summary tables.

The grid search is then narrowed to a high performance quadrant of the
search space by the model evaluator based on recommendations made by a
simple entropy minimization algorithm implemented in the "yogi"
supplementary package under the yogi.model\textsubscript{selection.butler} module --
see documentation for the various grid-narrowing strategies available.

In general, the recommended grid quickly eliminates under-performing
settings based on the sample probability of a setting appearing in a
set of finalists according to the scoring rankings. The selection
score is additionally influenced by a weighted sum of the scoring
ranks allowing for considerably tuning of the selection criterion.
For best results, a few different grid spaces should be explored to
corroborate eliminations.

After the recommendation is made, the granularity of the grid is
increased in the remaining ambiguous parameters and the process is
repeated.

Additionally/Alternatively,

\subsection{Genetic Algorithm}
\label{sec:org77f6fec}
\ldots{}\\

\section{ACKNOWLEDGMENTS}
\label{sec:org0f55089}
We acknowledge funding from the US Department of Energy SunShot program
under contract \#DOE DEEE005956. Use of the Center for Nanoscale
Materials, an Office of Science user facility, was supported by the U.S.
Department of Energy, Office of Science, Office of Basic Energy
Sciences, under Contract No. DE-AC02-06CH11357. We gratefully
acknowledge the computing resources provided on Bebop, a
high-performance computing cluster operated by the Laboratory Computing
Resource Center at Argonne National Laboratory. This research used
resources of the National Energy Research Scientific Computing Center, a
DOE Office of Science User Facility supported by the Office of Science
of the U.S. Department of Energy under Contract No. DE-AC02-05CH11231.
MYT would like to acknowledge support from the U.S. Department of
Energy, Office of Science, Office of Workforce Development for Teachers
and Scientists (WDTS) under the Science Undergraduate Laboratory
Internship (SULI) program. MJD was was supported by the U. S. Department
of Energy , Office of Basic Energy Sciences, Division of Chemical
Sciences, Geosciences, and Biosciences, under Contract No.
DE-AC02-06CH11357.

\subsection{Author Contributions}
\label{sec:orgade9ce1}
M.K.Y.C., R.F.K. and A.M.K. conceived the idea. A.M.K., M.Y.T. and
F.G.S. performed the DFT computations. A.M.K. and M.J.D. trained ML
models. All authors contributed to the discussion and writing of the
manuscript.

\subsection{Data Availability}
\label{sec:org8d52e0c}
DFT data and ML models are available from the corresponding author upon
reasonable request.

\subsection{Additional Information}
\label{sec:orgbc6ab16}
The authors declare no competing financial or non-financial interests.

Correspondence and requests for materials should be addressed to A.M.K.
(email:amannodi@purdue.edu).

\section{REFERENCES}
\label{sec:orga2443e3}
\bibliographystyle{authordate1}
\bibliography{../../../org/bibliotex/bibliotex}
\end{document}
